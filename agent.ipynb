{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We require the following setup for using gemeni model:\n",
    "1. https://cloud.google.com/docs/authentication/set-up-adc-local-dev-environment\n",
    "2. https://cloud.google.com/docs/authentication/application-default-credentials#GAC\n",
    "\n",
    "also need to enable billing etc to enable embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_vertexai import ChatVertexAI\n",
    "from langchain_google_vertexai import VertexAIEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "llm = ChatVertexAI(model=\"gemini-1.0-pro\")\n",
    "embeddings = VertexAIEmbeddings(model_name=\"text-embedding-004\")\n",
    "vector_store = Chroma(embedding_function=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "import bs4\n",
    "import uuid\n",
    "from typing import Annotated, Sequence\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_core.documents import Document\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.messages import SystemMessage, BaseMessage\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "from langgraph.graph import START, END, StateGraph, MessagesState\n",
    "from typing_extensions import List, TypedDict\n",
    "from IPython.display import Image, display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QA RAG model\n",
    "see: https://python.langchain.com/docs/tutorials/rag/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline for ingesting data from a source and indexing it (by semantic search for our case)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Load data with a data loader\n",
    "2. Break large documents into smaller chunks with text splitters to fit into model's finite context window\n",
    "3. Use vector store and embeddings model to store and index the splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and chunk contents of the blog\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\", # general llm agent blog for the curious\n",
    "               # help llm make sense of functions\n",
    "                \"https://xrpl-py.readthedocs.io/en/stable/source/snippets.html\",\n",
    "                \"https://xrpl-py.readthedocs.io/en/stable/source/xrpl.models.html\",\n",
    "                \"https://xrpl-py.readthedocs.io/en/stable/source/xrpl.wallet.html\",\n",
    "                \"https://xrpl-py.readthedocs.io/en/stable/source/xrpl.clients.html\",\n",
    "                \"https://xrpl-py.readthedocs.io/en/stable/source/xrpl.transaction.html\",\n",
    "                \"https://xrpl-py.readthedocs.io/en/stable/source/xrpl.ledger.html\",\n",
    "                \"https://xrpl-py.readthedocs.io/en/stable/source/xrpl.core.addresscodec.html\",\n",
    "                \"https://xrpl-py.readthedocs.io/en/stable/source/xrpl.utils.html\",\n",
    "                # context for answering questions related to the XRPL\n",
    "                \"https://xrpl.org/docs/introduction/what-is-the-xrp-ledger\",\n",
    "                \"https://xrpl.org/docs/introduction/what-is-xrp\",\n",
    "                \"https://xrpl.org/docs/introduction/crypto-wallets\",\n",
    "                \"https://xrpl.org/docs/introduction/transactions-and-requests\",\n",
    "                # context for answering questions related to the THENA protocol\n",
    "               \"https://docs.thena.fi/thena?ref=bnbchain.ghost.io\",\n",
    "               \"https://docs.thena.fi/thena/the-onboarding\",\n",
    "               \"https://docs.thena.fi/thena/the-spot-dex/swap-guide\",\n",
    "               \"https://docs.thena.fi/thena/the-spot-dex/limit-order\",\n",
    "               \"https://docs.thena.fi/thena/the-liquidity-pools/introduction-to-fusion\",\n",
    "               \"https://docs.thena.fi/thena/the-liquidity-pools/liquidity-pools-typology\",\n",
    "               \"https://docs.thena.fi/thena/the-liquidity-pools/earn-the\",\n",
    "               \"https://docs.thena.fi/thena/the-liquidity-pools/earn-trading-fees\",\n",
    "                ),\n",
    "    bs_kwargs=dict(\n",
    "        parse_only=bs4.SoupStrainer( \n",
    "            # Only keep post title, headers, and content from the full HTML.\n",
    "            class_=(\"post-content\", \"post-title\", \"post-header\")\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "docs = loader.load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "all_splits = text_splitter.split_documents(docs)\n",
    "\n",
    "# Index chunks\n",
    "_ = vector_store.add_documents(documents=all_splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieval and generation chain for taking user query at run time and retrieving data from index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Use a retriever to match against user query. Extending this to a tool allows models to rewrite user queries into more effective search queries. This also gives model a choice to either respond immediately or do RAG.\n",
    "2. ChatModel / LLM produces answer from prompt (which takes in user query and retrieved data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "template = \"\"\"Use the following pieces of context to answer the question at the end.\n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "Use three sentences maximum and keep the answer as concise as possible.\n",
    "Always say \"thanks for asking!\" at the end of the answer.\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Helpful Answer:\"\"\"\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "# Define state for application\n",
    "class State(TypedDict):\n",
    "    question: str\n",
    "    context: List[Document]\n",
    "    answer: str\n",
    "\n",
    "\n",
    "@tool(response_format=\"content_and_artifact\")\n",
    "def retrieve(query: str):\n",
    "    \"\"\"Retrieve information related to a query.\"\"\"\n",
    "    retrieved_docs = vector_store.similarity_search(\n",
    "        query, \n",
    "        k=2\n",
    "    )\n",
    "    serialized = \"\\n\\n\".join(\n",
    "        (f\"Source: {doc.metadata}\\n\" f\"Content: {doc.page_content}\")\n",
    "        for doc in retrieved_docs\n",
    "    )\n",
    "    return serialized, retrieved_docs\n",
    "\n",
    "# Step 1: Generate an AIMessage that may include a tool-call to be sent.\n",
    "def query_or_respond(state: MessagesState):\n",
    "    \"\"\"Generate tool call for retrieval or respond.\"\"\"\n",
    "    llm_with_tools = llm.bind_tools([retrieve])\n",
    "    response = llm_with_tools.invoke(state[\"messages\"])\n",
    "    # MessagesState appends messages to state instead of overwriting\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "\n",
    "# Step 2: Execute the retrieval.\n",
    "tools = ToolNode([retrieve])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent\n",
    "Now the control flow is defined by the reasoning capabilities of LLMs. Using agents allows you to offload additional discretion over the retrieval process. Although their behavior is less predictable than the above \"chain\", they are able to execute multiple retrieval steps in service of a query, or iterate on a single search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "memory = MemorySaver() # support multiple conversational turns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "websearch = TavilySearchResults(max_results=3)\n",
    "\n",
    "# mem_agent = create_react_agent(llm, [retrieve, websearch], checkpointer=memory) \n",
    "# display(Image(agent_executor.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentExecutor, create_tool_calling_agent\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder, PromptTemplate, SystemMessagePromptTemplate\n",
    "\n",
    "def create_tool_agent(llm: ChatVertexAI, tools: list, system_prompt: str):\n",
    "    \"\"\"Helper function to create agents with custom tools and system prompt\n",
    "    Args:\n",
    "        llm (ChatVertexAI): LLM for the agent\n",
    "        tools (list): list of tools the agent will use\n",
    "        system_prompt (str): text describing specific agent purpose\n",
    "\n",
    "    Returns:\n",
    "        executor (AgentExecutor): Runnable for the agent created.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Each worker node will be given a name and some tools.\n",
    "    \n",
    "    system_prompt_template = PromptTemplate(\n",
    "\n",
    "                template= system_prompt + \"\"\"\n",
    "                ONLY respond to the part of query relevant to your purpose.\n",
    "                IGNORE tasks you can't complete. \n",
    "                Use the following context to answer your query \n",
    "                if available: \\n {agent_history} \\n\n",
    "                \"\"\",\n",
    "                input_variables=[\"agent_history\"],\n",
    "            )\n",
    "\n",
    "    #define system message\n",
    "    system_message_prompt = SystemMessagePromptTemplate(prompt=system_prompt_template)\n",
    "\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [system_message_prompt,\n",
    "            MessagesPlaceholder(variable_name=\"messages\"),\n",
    "            MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "        ]\n",
    "    )\n",
    "    agent = create_tool_calling_agent(llm, tools, prompt)\n",
    "    executor = AgentExecutor(agent=agent, tools=tools, \n",
    "                return_intermediate_steps= True, verbose = False)\n",
    "    return executor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XRPL DEX Setup for agent tooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xrpl.clients import JsonRpcClient\n",
    "from xrpl.clients import WebsocketClient\n",
    "from xrpl.wallet import generate_faucet_wallet\n",
    "from xrpl.models.transactions import Payment\n",
    "from xrpl.transaction import submit_and_wait, autofill_and_sign\n",
    "from xrpl.models.requests.account_info import AccountInfo\n",
    "from xrpl.models.transactions import OfferCreate, OfferCancel\n",
    "from xrpl.models.currencies import IssuedCurrency, XRP\n",
    "from xrpl.models.requests import (\n",
    "\n",
    "    BookOffers,\n",
    ")\n",
    "from xrpl.utils import (\n",
    "    xrp_to_drops,\n",
    ")\n",
    "\n",
    "import pprint\n",
    "import requests\n",
    "from decimal import Decimal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool(response_format=\"content_and_artifact\")\n",
    "def get_json_rpc_client():\n",
    "    \"\"\"Create a JSON-RPC client for the XRP Ledger.\"\"\"\n",
    "    return JsonRpcClient(\"https://s.altnet.rippletest.net:51234/\")\n",
    "\n",
    "@tool(response_format=\"content_and_artifact\")\n",
    "def get_websocket_client():\n",
    "    \"\"\"Create a WebSocket client for the XRP Ledger.\"\"\"\n",
    "    return WebsocketClient(\"wss://s.altnet.rippletest.net:51233\")\n",
    "\n",
    "@tool(response_format=\"content_and_artifact\")\n",
    "def generate_wallet(client):\n",
    "    \"\"\"Generate a new wallet using the XRP Ledger.\"\"\"\n",
    "    return generate_faucet_wallet(client, debug=False)\n",
    "\n",
    "@tool(response_format=\"content_and_artifact\")\n",
    "def sign_and_submit_payment_txn(client, wallet, destination, amount):\n",
    "    \"\"\"Sign and submit a payment transaction to the XRP Ledger.\"\"\"\n",
    "    payment = Payment(\n",
    "        account=wallet.classic_address,\n",
    "        amount=xrp_to_drops(amount),\n",
    "        destination=destination\n",
    "    )\n",
    "    response = submit_and_wait(payment, client, wallet)\n",
    "    return response\n",
    "\n",
    "@tool(response_format=\"content_and_artifact\")\n",
    "def get_account_info(client, address):\n",
    "    \"\"\"Get account information from the XRP Ledger.\"\"\"\n",
    "    info = AccountInfo(\n",
    "        account=address,\n",
    "        edger_index=\"validated\",\n",
    "        strict=True,\n",
    "    )\n",
    "    response = client.request(info)\n",
    "    return response\n",
    "    \n",
    "\n",
    "### Trading specific functions\n",
    "# https://xrpl.org/docs/tutorials/how-tos/use-tokens/trade-in-the-decentralized-exchange#interactive-lookupoffers\n",
    "@tool(response_format=\"content_and_artifact\")\n",
    "def offer_lookup(wallet, client, currency_code_want, currency_issuer_want, want_value, currency_code_spend, currency_issuer_spend, spend_value, ledger_idx=\"current\"):\n",
    "    \"\"\"lookup offers on the XRP Ledger.\"\"\"\n",
    "    \n",
    "    we_want = {\n",
    "        \"currency\": IssuedCurrency(\n",
    "            currency=currency_code_want,\n",
    "            issuer=currency_issuer_want\n",
    "        ),\n",
    "        \"value\": want_value\n",
    "    }\n",
    "\n",
    "    we_spend = {\n",
    "        \"currency\": IssuedCurrency(\n",
    "            currency=currency_code_spend,\n",
    "            issuer=currency_issuer_spend\n",
    "        )\n",
    "    }\n",
    "\n",
    "    proposed_quality = Decimal(we_spend[\"value\"]) / Decimal(we_want[\"value\"])\n",
    "\n",
    "    orderbook_info = client.request(BookOffers(\n",
    "        taker=wallet.classic_address,\n",
    "        ledger_index=ledger_idx,\n",
    "        taker_gets=we_want[\"currency\"],\n",
    "        taker_pays=we_spend[\"currency\"],\n",
    "        limit=10,\n",
    "    ))\n",
    "\n",
    "    offers = orderbook_info.result.get(\"offers\", [])\n",
    "    want_amount = Decimal(we_want[\"value\"])\n",
    "    running_total = Decimal(0)\n",
    "    messages = []\n",
    "\n",
    "    if len(offers) == 0:\n",
    "        messages.append(\"No Offers in the matching book. Offer probably won't execute immediately.\")\n",
    "    else:\n",
    "        for o in offers:\n",
    "            if Decimal(o[\"quality\"]) <= proposed_quality:\n",
    "                messages.append(f\"Matching Offer found, funded with {o.get('owner_funds')} {we_want['currency']}\")\n",
    "                running_total += Decimal(o.get(\"owner_funds\", Decimal(0)))\n",
    "                if running_total >= want_amount:\n",
    "                    messages.append(\"Full Offer will probably fill\")\n",
    "                    break\n",
    "            else:\n",
    "                messages.append(\"Remaining orders too expensive.\")\n",
    "                break\n",
    "\n",
    "        messages.append(f\"Total matched: {min(running_total, want_amount)} {we_want['currency']}\")\n",
    "        if 0 < running_total < want_amount:\n",
    "            messages.append(f\"Remaining {want_amount - running_total} {we_want['currency']} would probably be placed on top of the order book.\")\n",
    "\n",
    "    if running_total == 0:\n",
    "        messages.append(\"Requesting second orderbook information...\")\n",
    "        orderbook2_info = client.request(\n",
    "            BookOffers(\n",
    "                taker=wallet.address,\n",
    "                ledger_index=\"current\",\n",
    "                taker_gets=we_spend[\"currency\"],\n",
    "                taker_pays=we_want[\"currency\"],\n",
    "                limit=10,\n",
    "            )\n",
    "        )\n",
    "        messages.append(f\"Orderbook2:\\n{pprint.pformat(orderbook2_info.result)}\")\n",
    "\n",
    "        offered_quality = Decimal(we_want[\"value\"]) / Decimal(we_spend[\"value\"])\n",
    "\n",
    "        tally_currency = we_spend[\"currency\"]\n",
    "        if isinstance(tally_currency, XRP):\n",
    "            tally_currency = f\"drops of {tally_currency}\"\n",
    "\n",
    "        offers2 = orderbook2_info.result.get(\"offers\", [])\n",
    "        running_total2 = Decimal(0)\n",
    "        if len(offers2) == 0:\n",
    "            messages.append(\"No similar Offers in the book. Ours would be the first.\")\n",
    "        else:\n",
    "            for o in offers2:\n",
    "                if Decimal(o[\"quality\"]) <= offered_quality:\n",
    "                    messages.append(f\"Existing offer found, funded with {o.get('owner_funds')} {tally_currency}\")\n",
    "                    running_total2 += Decimal(o.get(\"owner_funds\", Decimal(0)))\n",
    "                else:\n",
    "                    messages.append(\"Remaining orders are below where ours would be placed.\")\n",
    "                    break\n",
    "\n",
    "            messages.append(f\"Our Offer would be placed below at least {running_total2} {tally_currency}\")\n",
    "            if 0 < running_total2 < want_amount:\n",
    "                messages.append(f\"Remaining {want_amount - running_total2} {tally_currency} will probably be placed on top of the order book.\")\n",
    "\n",
    "    return messages\n",
    "\n",
    "\n",
    "# https://xrpl-py.readthedocs.io/en/stable/source/xrpl.models.transactions.html -> look for OfferCreate and OfferCancel\n",
    "@tool(response_format=\"content_and_artifact\")\n",
    "def create_offer(wallet, client, currency_code_want, currency_issuer_want, want_value, currency_code_spend, currency_issuer_spend, spend_value):\n",
    "    \"\"\"Create an offer to trade on the XRP Ledger. Returns True if successful.\"\"\"\n",
    "    we_want = {\n",
    "        \"currency\": IssuedCurrency(\n",
    "            currency=currency_code_want,\n",
    "            issuer=currency_issuer_want\n",
    "        ),\n",
    "        \"value\": want_value\n",
    "    }\n",
    "\n",
    "    we_spend = {\n",
    "        \"currency\": IssuedCurrency(\n",
    "            currency=currency_code_spend,\n",
    "            issuer=currency_issuer_spend\n",
    "        )\n",
    "    }\n",
    "    \n",
    "    tx = OfferCreate(\n",
    "        account=wallet.address,\n",
    "            taker_gets=we_spend[\"value\"],\n",
    "            taker_pays=we_want[\"currency\"].to_amount(we_want[\"value\"]),\n",
    "    )\n",
    "\n",
    "    signed_tx = autofill_and_sign(tx, client, wallet)\n",
    "\n",
    "    result = submit_and_wait(signed_tx, client)\n",
    "    return result.is_successful()\n",
    "\n",
    "# todo: implement cancel_offer function\n",
    "\n",
    "# meta info api for querying exchanges and tokens\n",
    "@tool(response_format=\"content_and_artifact\")\n",
    "def query_token_list(): # improvement: write to persistent storage and update every 24 hours\n",
    "    \"\"\"Query a list of tokens from the XRPL META API using http. Get back response as JSON. \n",
    "    Useful for getting individual token information needed for further queries.\"\"\"\n",
    "    response = requests.get(\"https://s1.xrplmeta.org/tokens\")\n",
    "    return response.json()\n",
    "\n",
    "@tool(response_format=\"content_and_artifact\") \n",
    "def query_token_info(token_currency: str, token_issuer: str):\n",
    "    \"\"\"\n",
    "    Query token information from the XRPL META API using http. Get back response as JSON.\n",
    "    Useful for getting links which provide more fundamental information about the token,\n",
    "    as well as inherent properties of the token such as trust level.\n",
    "    \"\"\"\n",
    "    token_identifier = f\"{token_currency}:{token_issuer}\"\n",
    "    response = requests.get(f\"https://s1.xrplmeta.org/token/{token_identifier}\")\n",
    "    return response.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Continuation of agent prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_prompt = \"\"\" You are a assistant for performing research on market sentiment of a cryto asset.\n",
    "        You are to gauge whether the sentiment is positive, negative or neutral based on news and statements\n",
    "        made by influential sources in the cryptocurrency space. Also, weigh the sentiment based on the profile of the source.\n",
    "        For example, a statement from a well-known cryptocurrency influencer may have more weight than a random twitter user with less than average number of followers.\n",
    "        You must also take into account of whether the opinion is based on facts or speculation, and if the source has a history of being accurate.\n",
    "        Use your tools to answer questions. If you do not have a tool to\n",
    "        answer the question, say so. \"\"\"\n",
    "\n",
    "sentiment_agent = create_tool_agent(llm=llm, tools = [retrieve, websearch], # todo: add twitter, governance, news tools\n",
    "              system_prompt = sentiment_prompt)\n",
    "\n",
    "risk_prompt = \"\"\" You are a assistant for performing risk analysis and compliance on a crypto asset.\n",
    "        You are to assess the risk of investing in a cryptocurrency based on the information available.\n",
    "        You must consider the technology behind the cryptocurrency, the team behind the project, the market conditions, and the regulatory environment.\n",
    "        Also, you will assess if this project satisfies regulatory requirements and if it is compliant with the law.\n",
    "        Use your tools to complete requests. If you do not have a tool to\n",
    "       complete the request, say so. \"\"\"\n",
    "\n",
    "risk_agent = create_tool_agent(llm=llm, tools = [retrieve, websearch], \n",
    "                    system_prompt = risk_prompt)\n",
    "\n",
    "\n",
    "thena_api_prompt = \"\"\" You are an assistant for performing action such as querying user wallet status, trading, swapping and liquidity provision to THENA blockchain ecosystem based on the user's request if any.\n",
    "        Use your tools to complete requests. If you do not have a tool to\n",
    "       complete the request, say so. \"\"\"\n",
    "\n",
    "thena_api_agent = create_tool_agent(llm=llm, tools = [], \n",
    "                    system_prompt = thena_api_prompt)\n",
    "\n",
    "\n",
    "xrpl_api_prompt = \"\"\" You are an assistant for performing action such as generating testnet wallet, querying user wallet status, trading, swapping and liquidity provision to Ripple Ledger (XRPL) blockchain ecosystem based on the user's request if any.\n",
    "        Use your tools to complete requests. \n",
    "        If you need more information to call tools, ask for it and guide the user to knowing what tools you have.\n",
    "        If you do not have a tool to\n",
    "       complete the request, say so. \"\"\"\n",
    "\n",
    "\n",
    "xrpl_api_tools = [retrieve, websearch, get_json_rpc_client, get_websocket_client, generate_wallet, sign_and_submit_payment_txn, get_account_info, offer_lookup, create_offer, query_token_list, query_token_info]\n",
    "xrpl_api_agent = create_tool_agent(llm=llm, tools = xrpl_api_tools, # todo: tools for staking, LPing, swapping etc\n",
    "        system_prompt = xrpl_api_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "system_prompt_template = PromptTemplate(\n",
    "\n",
    "      template= \"\"\" You are a helpful assistant that summarises agent history \n",
    "                      in response to the original user query below. \n",
    "                      SUMMARISE ALL THE OUTPUTS AND TOOLS USED in agent_history.\n",
    "                      The agent history is as follows: \n",
    "                        \\n{agent_history}\\n\"\"\",\n",
    "                input_variables=[\"agent_history\"],  )\n",
    "\n",
    "system_message_prompt = SystemMessagePromptTemplate(prompt=system_prompt_template)\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        system_message_prompt,\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    ])\n",
    "\n",
    "comms_agent = (prompt| llm) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from enum import Enum\n",
    "members = [\"Sentiment\", \"Risk\", \"THENA_API\", \"XRPL_API\", \"Communicate\"]\n",
    "\n",
    "#create options map for the supervisor output parser.\n",
    "member_options = {member:member for member in members}\n",
    "\n",
    "#create Enum object\n",
    "MemberEnum = Enum('MemberEnum', member_options)\n",
    "\n",
    "from pydantic import BaseModel\n",
    "\n",
    "#force Supervisor to pick from options defined above\n",
    "# return a dictionary specifying the next agent to call \n",
    "#under key next.\n",
    "class SupervisorOutput(BaseModel):\n",
    "    #defaults to communication agent\n",
    "    next: MemberEnum = MemberEnum.Communicate\n",
    "\n",
    "\n",
    "system_prompt = (\n",
    "    \"\"\"You are a supervisor tasked with managing a conversation between the\n",
    "    crew of workers:  {members}. Given the following user request, \n",
    "    and crew responses respond with the worker to act next.\n",
    "\n",
    "    The crew will mainly be assisting with providing financial advice regarding blockchain research,\n",
    "    it is fine for you to provide such advices as users are using information for educational purposes.\n",
    "\n",
    "    Each worker will perform a task and respond with their results and status. \n",
    "    When finished with the task, route to communicate to deliver the result to \n",
    "    user. Given the conversation and crew history below, who should act next?\n",
    "    You are to simulate a ReAct agent by observing crew agent outputs, \n",
    "    reasoning about whether to pass outputs\n",
    "    to other agents again to act using their tools or to the user.\n",
    "    API agents should take into account of sentiment and risk analysis.\n",
    "    Analysis should take into account of overall history.\n",
    "    Select one of: {options} \n",
    "    \\n{format_instructions}\\n\"\"\"\n",
    ")\n",
    "# Our team supervisor is an LLM node. It just picks the next agent to process\n",
    "# and decides when the work is completed\n",
    "\n",
    "# Using openai function calling can make output parsing easier for us\n",
    "supervisor_parser = JsonOutputParser(pydantic_object=SupervisorOutput)\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "        MessagesPlaceholder(variable_name=\"agent_history\")\n",
    "       \n",
    "    ]\n",
    ").partial(options=str(members), members=\", \".join(members), \n",
    "    format_instructions = supervisor_parser.get_format_instructions())\n",
    "\n",
    "\n",
    "supervisor_chain = (\n",
    "    prompt | llm |supervisor_parser\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain_core.messages import AIMessage\n",
    "import operator\n",
    "\n",
    "# For agents in the crew \n",
    "def crew_nodes(state, crew_member, name):\n",
    "    #read the last message in the message history.\n",
    "    input = {'messages': [state['messages'][-1]], \n",
    "                'agent_history' : state['agent_history']}\n",
    "    result = crew_member.invoke(input)\n",
    "    #add response to the agent history.\n",
    "    return {\"agent_history\": [AIMessage(content= result[\"output\"], \n",
    "              additional_kwargs= {'intermediate_steps' : result['intermediate_steps']}, \n",
    "              name=name)]}\n",
    "\n",
    "def comms_node(state):\n",
    "    #read the last message in the message history.\n",
    "    input = {'messages': [state['messages'][-1]],\n",
    "                     'agent_history' : state['agent_history']}\n",
    "    result = comms_agent.invoke(input)\n",
    "    #respond back to the user.\n",
    "    return {\"messages\": [result]}\n",
    "\n",
    "# The agent state is the input to each node in the graph\n",
    "class AgentState(TypedDict):\n",
    "    # The annotation tells the graph that new messages will always\n",
    "    # be added to the current states\n",
    "    messages: Annotated[Sequence[BaseMessage], operator.add] # annotate field with a reducer as metadata\n",
    "    # The 'next' field indicates where to route to next\n",
    "    next: str \n",
    "    agent_history: Annotated[Sequence[BaseMessage], operator.add]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from functools import partial\n",
    "\n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "# mem_node = partial(crew_nodes, crew_member=mem_agent, name=\"Memory\")\n",
    "sentiment_node = partial(crew_nodes, crew_member=sentiment_agent, name=\"Sentiment\")\n",
    "risk_node = partial(crew_nodes, crew_member=risk_agent, name=\"Risk\")\n",
    "thena_api_node = partial(crew_nodes, crew_member=thena_api_agent, name=\"THENA_API\")\n",
    "xrpl_api_node = partial(crew_nodes, crew_member=xrpl_api_agent, name=\"XRPL_API\")\n",
    "\n",
    "# workflow.add_node(\"Mem\", mem_node)\n",
    "workflow.add_node(\"Sentiment\", sentiment_node)\n",
    "workflow.add_node(\"Risk\", risk_node)\n",
    "workflow.add_node(\"THENA_API\", thena_api_node)\n",
    "workflow.add_node(\"XRPL_API\", xrpl_api_node)\n",
    "workflow.add_node(\"Communicate\", comms_node )\n",
    "workflow.add_node(\"Supervisor\", supervisor_chain)\n",
    "workflow.set_entry_point(\"Supervisor\")\n",
    "# workflow.add_edge('Mem', \"Supervisor\")\n",
    "workflow.add_edge('Sentiment', \"Supervisor\")\n",
    "workflow.add_edge('Risk', \"Supervisor\")\n",
    "workflow.add_edge('THENA_API', \"Supervisor\")\n",
    "workflow.add_edge('XRPL_API', \"Supervisor\")\n",
    "workflow.add_edge('Communicate', END) \n",
    "# end loop at communication agent.\n",
    "\n",
    "# The supervisor populates the \"next\" field in the graph state\n",
    "# which routes to a node or finishes\n",
    "workflow.add_conditional_edges(\"Supervisor\", lambda x: x[\"next\"], member_options)\n",
    "\n",
    "graph = workflow.compile(checkpointer=memory)\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests / Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: We still have a few error outputs to resolve, likely due to formatting issues of content returned to the model by the tools. \n",
    "This can be ignored for now, as the model is still able to generate responses. If we were to deploy this with a chat interface the issues can be masked.\n",
    "Also, due to token limits, the model may not be able to generate as comprehensive responses as expected. \n",
    "This can be resolved by using a larger model or breaking down the query into smaller chunks to be repeated.\n",
    "\n",
    "Please scroll all the way down to see generated responses or expand the cell in a new tab to see the full output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Can you suggest a few trustworthy investments on XRPL based on news and scores?\n"
     ]
    },
    {
     "ename": "OutputParserException",
     "evalue": "Invalid json output: ##  Solocoin's Fundamental Analysis on XRPL:\n\n**Solocoin (SOLO)** is a community-driven meme coin on the XRPL that gained significant popularity and quickly reached a top 50 position on CoinMarketCap soon after its launch.\n\n**Fundamental Analysis:**\n\n*   **Tokenomics:** SOLO has a total supply of 1 trillion tokens, with 50% allocated to the public sale, 20% to the team, 15% to rewards, 10% to marketing, and 5% to liquidity. However, there have been concerns about the tokenomics being \"centralized,\" as 23% of the solo coins were reportedly allocated to just five wallets.\n*   **Use Case:** Currently, SOLO appears to be primarily a **speculative** asset without clearly defined use cases beyond being a meme coin. The SOLO network also offers features like token burning, which helps reduce token supply and potentially increase value. It has a low market cap and high 24h trading volume, implying potential for growth but also volatility.\n*   **Community:** SOLO has a strong and enthusiastic community, which played a significant role in its initial popularity. \n*   **News and Media:**\n    *   SOLO was listed on LATOKEN on March 18, 2023, which likely contributed to a slight price increase at that time.\n    *   The SOLO ecosystem was reportedly in discussions with a Chinese consortium that may allow solocoin to be \"incorporated into some Chinese enterprises and industries\".\n    *   The project had shown \"great growth\" and its price action showed \"positive performance on the chart\" during a May 2023 article.\n\n**Potential Risks:**\n\n*   **Lack of clear use case:** As with other meme coins, a lack of strong utility might hinder sustainable growth.\n*   **Competition:** SOLO faces significant competition from well-established meme coins, such as DOGE and SHIB.\n*   **Volatility:** As a young token, it experiences large price swings, leading to potential losses for investors.\n*   **Centralization Concerns:** The significant share of tokens held by few wallets might raise questions about decentralization.\n\n**Overall:**\n\nBased on the fundamental analysis, SOLO shows potential for growth, but also carries notable risks. It's crucial to understand the project's limitations, conduct in-depth research, and consider your risk tolerance before making any investment decisions.\n\n**Additional Resources:**\n\n*   [SOLO Price Live](https://coinmarketcap.com/currencies/solocoin/)\n*   [SOLO Project Links](https://solocoin.io/#links)\n*   [SOLO Official Twitter](https://twitter.com/solocoinofficial)\n*   [Solocoin News](https://www.newsbtc.com/tag/solocoin/)\n\n**Disclaimer:** This is not financial advice, and the information presented should not be considered as such. Always do your own research before investing in any cryptocurrency.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m~/tragents/.venv/lib/python3.10/site-packages/langchain_core/output_parsers/json.py:84\u001b[0m, in \u001b[0;36mJsonOutputParser.parse_result\u001b[0;34m(self, result, partial)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 84\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparse_json_markdown\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m JSONDecodeError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/tragents/.venv/lib/python3.10/site-packages/langchain_core/utils/json.py:147\u001b[0m, in \u001b[0;36mparse_json_markdown\u001b[0;34m(json_string, parser)\u001b[0m\n\u001b[1;32m    146\u001b[0m         json_str \u001b[38;5;241m=\u001b[39m match\u001b[38;5;241m.\u001b[39mgroup(\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m--> 147\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_parse_json\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson_str\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparser\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparser\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/tragents/.venv/lib/python3.10/site-packages/langchain_core/utils/json.py:163\u001b[0m, in \u001b[0;36m_parse_json\u001b[0;34m(json_str, parser)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;66;03m# Parse the JSON string into a Python dictionary\u001b[39;00m\n\u001b[0;32m--> 163\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson_str\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/tragents/.venv/lib/python3.10/site-packages/langchain_core/utils/json.py:118\u001b[0m, in \u001b[0;36mparse_partial_json\u001b[0;34m(s, strict)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;66;03m# If we got here, we ran out of characters to remove\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;66;03m# and still couldn't parse the string as JSON, so return the parse error\u001b[39;00m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;66;03m# for the original string.\u001b[39;00m\n\u001b[0;32m--> 118\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstrict\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.10/json/__init__.py:359\u001b[0m, in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    358\u001b[0m     kw[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparse_constant\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m parse_constant\n\u001b[0;32m--> 359\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.10/json/decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;124;03mcontaining a JSON document).\u001b[39;00m\n\u001b[1;32m    335\u001b[0m \n\u001b[1;32m    336\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 337\u001b[0m obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    338\u001b[0m end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n",
      "File \u001b[0;32m/usr/lib/python3.10/json/decoder.py:355\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m--> 355\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpecting value\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, err\u001b[38;5;241m.\u001b[39mvalue) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    356\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj, end\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mOutputParserException\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[73], line 11\u001b[0m\n\u001b[1;32m      6\u001b[0m messages \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      7\u001b[0m     HumanMessage(content\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan you suggest a few trustworthy investments on XRPL based on news and scores?\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      8\u001b[0m ]\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# input_message = {\"type\": \"user\", \"content\": \"hi! I'm bob\"}\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m graph\u001b[38;5;241m.\u001b[39mstream({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m: messages}, config, stream_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     12\u001b[0m     chunk[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mpretty_print()\n",
      "File \u001b[0;32m~/tragents/.venv/lib/python3.10/site-packages/langgraph/pregel/__init__.py:1656\u001b[0m, in \u001b[0;36mPregel.stream\u001b[0;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, subgraphs)\u001b[0m\n\u001b[1;32m   1650\u001b[0m     \u001b[38;5;66;03m# Similarly to Bulk Synchronous Parallel / Pregel model\u001b[39;00m\n\u001b[1;32m   1651\u001b[0m     \u001b[38;5;66;03m# computation proceeds in steps, while there are channel updates\u001b[39;00m\n\u001b[1;32m   1652\u001b[0m     \u001b[38;5;66;03m# channel updates from step N are only visible in step N+1\u001b[39;00m\n\u001b[1;32m   1653\u001b[0m     \u001b[38;5;66;03m# channels are guaranteed to be immutable for the duration of the step,\u001b[39;00m\n\u001b[1;32m   1654\u001b[0m     \u001b[38;5;66;03m# with channel updates applied only at the transition between steps\u001b[39;00m\n\u001b[1;32m   1655\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mtick(input_keys\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_channels):\n\u001b[0;32m-> 1656\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m runner\u001b[38;5;241m.\u001b[39mtick(\n\u001b[1;32m   1657\u001b[0m             loop\u001b[38;5;241m.\u001b[39mtasks\u001b[38;5;241m.\u001b[39mvalues(),\n\u001b[1;32m   1658\u001b[0m             timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_timeout,\n\u001b[1;32m   1659\u001b[0m             retry_policy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretry_policy,\n\u001b[1;32m   1660\u001b[0m             get_waiter\u001b[38;5;241m=\u001b[39mget_waiter,\n\u001b[1;32m   1661\u001b[0m         ):\n\u001b[1;32m   1662\u001b[0m             \u001b[38;5;66;03m# emit output\u001b[39;00m\n\u001b[1;32m   1663\u001b[0m             \u001b[38;5;28;01myield from\u001b[39;00m output()\n\u001b[1;32m   1664\u001b[0m \u001b[38;5;66;03m# emit output\u001b[39;00m\n",
      "File \u001b[0;32m~/tragents/.venv/lib/python3.10/site-packages/langgraph/pregel/runner.py:167\u001b[0m, in \u001b[0;36mPregelRunner.tick\u001b[0;34m(self, tasks, reraise, timeout, retry_policy, get_waiter)\u001b[0m\n\u001b[1;32m    165\u001b[0m t \u001b[38;5;241m=\u001b[39m tasks[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 167\u001b[0m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_SEND\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwriter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcall\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    175\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m~/tragents/.venv/lib/python3.10/site-packages/langgraph/pregel/retry.py:40\u001b[0m, in \u001b[0;36mrun_with_retry\u001b[0;34m(task, retry_policy, configurable)\u001b[0m\n\u001b[1;32m     38\u001b[0m     task\u001b[38;5;241m.\u001b[39mwrites\u001b[38;5;241m.\u001b[39mclear()\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[0;32m---> 40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m     42\u001b[0m     ns: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "File \u001b[0;32m~/tragents/.venv/lib/python3.10/site-packages/langgraph/utils/runnable.py:410\u001b[0m, in \u001b[0;36mRunnableSeq.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    408\u001b[0m             \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m step\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    409\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 410\u001b[0m             \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    411\u001b[0m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[1;32m    412\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/tragents/.venv/lib/python3.10/site-packages/langchain_core/output_parsers/base.py:183\u001b[0m, in \u001b[0;36mBaseOutputParser.invoke\u001b[0;34m(self, input, config)\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvoke\u001b[39m(\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Union[\u001b[38;5;28mstr\u001b[39m, BaseMessage], config: Optional[RunnableConfig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    181\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[1;32m    182\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28minput\u001b[39m, BaseMessage):\n\u001b[0;32m--> 183\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_with_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minner_input\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse_result\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[43m                \u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatGeneration\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minner_input\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    187\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    188\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    190\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    191\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    192\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_with_config(\n\u001b[1;32m    193\u001b[0m             \u001b[38;5;28;01mlambda\u001b[39;00m inner_input: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparse_result([Generation(text\u001b[38;5;241m=\u001b[39minner_input)]),\n\u001b[1;32m    194\u001b[0m             \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m    195\u001b[0m             config,\n\u001b[1;32m    196\u001b[0m             run_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparser\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    197\u001b[0m         )\n",
      "File \u001b[0;32m~/tragents/.venv/lib/python3.10/site-packages/langchain_core/runnables/base.py:1786\u001b[0m, in \u001b[0;36mRunnable._call_with_config\u001b[0;34m(self, func, input, config, run_type, serialized, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m     context \u001b[38;5;241m=\u001b[39m copy_context()\n\u001b[1;32m   1783\u001b[0m     context\u001b[38;5;241m.\u001b[39mrun(_set_config_context, child_config)\n\u001b[1;32m   1784\u001b[0m     output \u001b[38;5;241m=\u001b[39m cast(\n\u001b[1;32m   1785\u001b[0m         Output,\n\u001b[0;32m-> 1786\u001b[0m         \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1787\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcall_func_with_variable_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m   1788\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m   1789\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m   1790\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1791\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1792\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1793\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m   1794\u001b[0m     )\n\u001b[1;32m   1795\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1796\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[0;32m~/tragents/.venv/lib/python3.10/site-packages/langchain_core/runnables/config.py:398\u001b[0m, in \u001b[0;36mcall_func_with_variable_args\u001b[0;34m(func, input, config, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    396\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m accepts_run_manager(func):\n\u001b[1;32m    397\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m run_manager\n\u001b[0;32m--> 398\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/tragents/.venv/lib/python3.10/site-packages/langchain_core/output_parsers/base.py:184\u001b[0m, in \u001b[0;36mBaseOutputParser.invoke.<locals>.<lambda>\u001b[0;34m(inner_input)\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvoke\u001b[39m(\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Union[\u001b[38;5;28mstr\u001b[39m, BaseMessage], config: Optional[RunnableConfig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    181\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[1;32m    182\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28minput\u001b[39m, BaseMessage):\n\u001b[1;32m    183\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_with_config(\n\u001b[0;32m--> 184\u001b[0m             \u001b[38;5;28;01mlambda\u001b[39;00m inner_input: \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse_result\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[43m                \u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatGeneration\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minner_input\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    187\u001b[0m             \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m    188\u001b[0m             config,\n\u001b[1;32m    189\u001b[0m             run_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparser\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    190\u001b[0m         )\n\u001b[1;32m    191\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    192\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_with_config(\n\u001b[1;32m    193\u001b[0m             \u001b[38;5;28;01mlambda\u001b[39;00m inner_input: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparse_result([Generation(text\u001b[38;5;241m=\u001b[39minner_input)]),\n\u001b[1;32m    194\u001b[0m             \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m    195\u001b[0m             config,\n\u001b[1;32m    196\u001b[0m             run_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparser\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    197\u001b[0m         )\n",
      "File \u001b[0;32m~/tragents/.venv/lib/python3.10/site-packages/langchain_core/output_parsers/json.py:87\u001b[0m, in \u001b[0;36mJsonOutputParser.parse_result\u001b[0;34m(self, result, partial)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m JSONDecodeError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     86\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid json output: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtext\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 87\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m OutputParserException(msg, llm_output\u001b[38;5;241m=\u001b[39mtext) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[0;31mOutputParserException\u001b[0m: Invalid json output: ##  Solocoin's Fundamental Analysis on XRPL:\n\n**Solocoin (SOLO)** is a community-driven meme coin on the XRPL that gained significant popularity and quickly reached a top 50 position on CoinMarketCap soon after its launch.\n\n**Fundamental Analysis:**\n\n*   **Tokenomics:** SOLO has a total supply of 1 trillion tokens, with 50% allocated to the public sale, 20% to the team, 15% to rewards, 10% to marketing, and 5% to liquidity. However, there have been concerns about the tokenomics being \"centralized,\" as 23% of the solo coins were reportedly allocated to just five wallets.\n*   **Use Case:** Currently, SOLO appears to be primarily a **speculative** asset without clearly defined use cases beyond being a meme coin. The SOLO network also offers features like token burning, which helps reduce token supply and potentially increase value. It has a low market cap and high 24h trading volume, implying potential for growth but also volatility.\n*   **Community:** SOLO has a strong and enthusiastic community, which played a significant role in its initial popularity. \n*   **News and Media:**\n    *   SOLO was listed on LATOKEN on March 18, 2023, which likely contributed to a slight price increase at that time.\n    *   The SOLO ecosystem was reportedly in discussions with a Chinese consortium that may allow solocoin to be \"incorporated into some Chinese enterprises and industries\".\n    *   The project had shown \"great growth\" and its price action showed \"positive performance on the chart\" during a May 2023 article.\n\n**Potential Risks:**\n\n*   **Lack of clear use case:** As with other meme coins, a lack of strong utility might hinder sustainable growth.\n*   **Competition:** SOLO faces significant competition from well-established meme coins, such as DOGE and SHIB.\n*   **Volatility:** As a young token, it experiences large price swings, leading to potential losses for investors.\n*   **Centralization Concerns:** The significant share of tokens held by few wallets might raise questions about decentralization.\n\n**Overall:**\n\nBased on the fundamental analysis, SOLO shows potential for growth, but also carries notable risks. It's crucial to understand the project's limitations, conduct in-depth research, and consider your risk tolerance before making any investment decisions.\n\n**Additional Resources:**\n\n*   [SOLO Price Live](https://coinmarketcap.com/currencies/solocoin/)\n*   [SOLO Project Links](https://solocoin.io/#links)\n*   [SOLO Official Twitter](https://twitter.com/solocoinofficial)\n*   [Solocoin News](https://www.newsbtc.com/tag/solocoin/)\n\n**Disclaimer:** This is not financial advice, and the information presented should not be considered as such. Always do your own research before investing in any cryptocurrency."
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "# Specify a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "messages = [\n",
    "    HumanMessage(content=\"Can you suggest a few trustworthy investments on XRPL based on news and scores?\")\n",
    "]\n",
    "\n",
    "# input_message = {\"type\": \"user\", \"content\": \"hi! I'm bob\"}\n",
    "for chunk in graph.stream({\"messages\": messages}, config, stream_mode=\"values\"):\n",
    "    chunk[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above, we can see that the supervising agent knows to delegate tasks appropriately as there was risk analysis and fundamental analysis. We can also see that the worker agents are able to use the tools provided to do web search and query ripple ledger for content such as what coins are available on the ledger (in this case SOLOCOIN is one of them, more would have been suggested if there was no output token limit). We can also see that the model knows to perform a second call to specific token (SOLOCOIN) to get more information about it such as its dscription and associated resources."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other questions that can be asked, examples are:\n",
    "- “Perform a due diligence on token issuers and tell me about the trustworthiness of solocoin”\n",
    "- “Search the internet on tweets of key opinion leaders about their sentiment on dogecoin”\n",
    "- “Fetch for me the market activity of Ripple in the past 24 hours” -> “why should I invest, at what price point, and for how long should I hold this position?”\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
